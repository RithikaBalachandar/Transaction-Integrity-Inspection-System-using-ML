# -*- coding: utf-8 -*-
"""Transaction integrity inspection system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NUrWe2xaLev3kEhSMPspsGjjq_0EYiLx

# ***Transaction Integrity Inspection System***

# **Importing packages**
"""

import numpy as np
import pandas as pd

"""## **Loading the dataset**

"""

from google.colab import drive
drive.mount('/content/drive')

data=pd.read_csv('/content/drive/MyDrive/Final year project /Transaction_dataset1.csv')

"""**Retrieving the First 5 and last 5 values**

"""

data.head(10)

data.tail()

data.info()

data.describe()

print(data.isna().sum())

data.keys()

data.shape

print(data.duplicated().sum())

data['type'].value_counts()

import matplotlib.pyplot as plt
import matplotlib.cm as cm
import seaborn as sns

type = data['type'].value_counts()

# Get the transaction types and their counts
transactions = type.index
quantity = type.values

# Define a list of darker colors
colors = ['pink','cyan','bisque','teal','yellow']

# Create the pie chart
fig, ax = plt.subplots()
ax.pie(quantity, labels=transactions, autopct='%1.1f%%', startangle=90, colors=colors)
ax.axis('equal')  # Ensures the pie chart is a perfect circle
ax.set_title('Distribution of Transaction Type')

plt.show()

fig = plt.figure(figsize=(10, 7))
data['type'].value_counts(normalize=True).plot(kind='bar',color='orange')
plt.xlabel("Type")
plt.ylabel("Value Count")
plt.show()

data['isFraud'].value_counts()

sns.countplot(data=data,x="isFraud",color='aqua')

"""# **Removing unwanted columns**"""

data = data.drop(['nameOrig','nameDest','isFlaggedFraud','step','oldbalanceDest','newbalanceDest'], axis=1)

print(data.keys())

"""# **Removal of outliers**"""

sns.boxplot(data)

num=[var for var in data.columns if data[var].dtype!='O' and var!='isFraud']
num

from scipy import stats
for x in num:
  bmi_z_score=stats.zscore(data[x])
  data=data[np.abs(bmi_z_score)<=3]

sns.boxplot(data)

"""## **Data preprocessing**

### **Label Encoding**
"""

from sklearn.preprocessing import LabelEncoder

le=LabelEncoder()
data["type"]=le.fit_transform(data["type"])

data["type"].value_counts()

# Dividing the dataset into dependent and independent y and x respectively
x=data.drop("isFraud",axis=1)
y=data["isFraud"]

x.head()

y.head()

"""## **Scaling data**

"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
x = scaler.fit_transform(x)

"""## **Splitting the data:**

"""

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0,test_size=0.2)

"""# **MODEL BUILDING :**

# **Using SUPPORT VECTOR MACHINE (SVM)**

## **Importing needed modules**
"""

from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report

scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

from sklearn.linear_model import SGDClassifier
model = SGDClassifier(loss='hinge')

model.fit(x_train, y_train)

y_pred = model.predict(x_test)

print("Accuracy:", accuracy_score(y_test, y_pred))

"""## **SVM using linear regression**"""

# model = SVC(kernel='linear')

# model.fit(x_train, y_train)

# y_pred = model.predict(x_test)

# print("Accuracy:", accuracy_score(y_test, y_pred))

svc= SVC()

svc.fit(x_train,y_train)

y_test_predict=svc.predict(x_test)
test_accuracy=accuracy_score(y_test,y_test_predict)
test_accuracy

y_train_predict=svc.predict(x_train)
train_accuracy=accuracy_score(y_train,y_train_predict)
train_accuracy

"""# **Using RANDOM FOREST**

## **Importing needed modules**

### **Balancing the data using SMOTE technique**
"""

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
x_train, y_train = smote.fit_resample(x_train, y_train)

from sklearn.ensemble import RandomForestClassifier

rfc=RandomForestClassifier(class_weight='balanced', random_state=42)

rfc.fit(x_train, y_train)

"""### **Evaluating the Test accuracy**"""

y_test_predict=rfc.predict(x_test)

test_accuracy=accuracy_score(y_test,y_test_predict)
test_accuracy

"""### **Evaluating the Train accuracy**"""

y_train_predict=rfc.predict(x_train)
train_accuracy=accuracy_score(y_train,y_train_predict)
train_accuracy

"""### **Generating Classification Report**"""

# from sklearn.metrics import classification_report

print(classification_report(y_test, y_test_predict))

"""# **Saving the model as pickle file**"""

import pickle

with open('RFC_model.pkl', 'wb') as file:
    pickle.dump(rfc, file)

from google.colab import files
files.download('RFC_model.pkl')

import joblib

joblib.dump(rfc, 'fraud_detection_model.pkl')

from google.colab import files
files.download('fraud_detection_model.pkl')

joblib.dump(scaler,'scaler.pkl')

# model=pickle.load(open(file,"rb"))
filename= 'fraud_detection_model.pkl'
pickle.dump(rfc, open(filename, 'wb'))

model=pickle.load(open(filename,"rb"))

scaler = joblib.load('scaler.pkl')  # Load scaler